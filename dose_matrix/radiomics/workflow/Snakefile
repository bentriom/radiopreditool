
from functools import reduce
import pandas as pd
import os, sys, logging
sys.path.append("./workflow/scripts/")
import csv2nii, feature_extractor, check_dataset, report_checks, trainset, learning
from radiopreditool_utils import setup_logger, get_ncpus

MODEL_NAME = config["MODEL_NAME"]
RADIOMICS_NAME = config["RADIOMICS_NAME"] if "RADIOMICS_NAME" in config else MODEL_NAME
RADIOMICS_PARAMS_FILE = config["RADIOMICS_PARAMS_FILE"]
FCCSS_CLINICAL_VARIABLES = config["FCCSS_CLINICAL_VARIABLES"]
LABELS_SUPER_T_VOI = config["LABELS_SUPER_T_VOI"] if "LABELS_SUPER_T_VOI" in config else [""]
LABELS_T_VOI = config["LABELS_T_VOI"] if "LABELS_T_VOI" in config else [""]
EVENT_COL = "Pathologie_cardiaque"
DATE_EVENT_COL = "date_pathol_cardiaque"
NB_ESTIM_SCORE_MODELS = 50

DOSES_DATASET_DIR = config["DOSES_DATASET_DIR"]
DOSES_DATASET_SUBDIRS = config["DOSES_DATASET_SUBDIRS"] if "DOSES_DATASET_SUBDIRS" in config else [""]
FCCSS_CLINICAL_DATASET = config["FCCSS_CLINICAL_DATASET"]
RESULTS_DIR = config["RESULTS_DIR"]
NII_DIR = RESULTS_DIR + "nii/"
METADATA_DIR = RESULTS_DIR + "metadata/"
RADIOMICS_DIR = RESULTS_DIR + "extraction/" + RADIOMICS_NAME + "/"
ANALYZES_DIR = RESULTS_DIR + "analyzes/" + MODEL_NAME + "/"

BASELINE_MODELS_COX = ["1320_mean", "1320_dosesvol"]
BASELINE_MODELS_LASSO = ["1320_dosesvol_lasso"]
COX_RADIOMICS_LASSO = ["32X_radiomics_lasso", "32X_radiomics_features_hclust_lasso", \
                       "1320_radiomics_lasso", "1320_radiomics_features_hclust_lasso"]
RSF_RADIOMICS_ALL = ["model_32X_all", "model_1320_all"]
RSF_RADIOMICS_FE_HCLUST = ["model_32X_features_hclust_corr", "model_1320_features_hclust_corr"]

# Create useful variables for rules based on configuration
def addslash(subdir):
    return (subdir if subdir == "" else subdir + "/")
def get_patient_file(newdosi_file):
    split_newdosi = newdosi_file.split("_")
    return split_newdosi[0] + "_" + split_newdosi[1] + "_" + split_newdosi[2][0:-1]
list_newdosi_files = [addslash(subdir) + f.split(".")[0]  for subdir in DOSES_DATASET_SUBDIRS for f in os.listdir(DOSES_DATASET_DIR + subdir) if ".csv.gz" in f]
list_newdosi_patients = list(set([get_patient_file(newdosi) for newdosi in list_newdosi_files]))
str_cmd_dataset_subdirs = reduce(lambda a,b:a+b, [sdir + "," for sdir in DOSES_DATASET_SUBDIRS])[0:-1]

# Command to gather the computed radiomics
cmd_concatenate_radiomics = "cat '" + RADIOMICS_DIR + "header.csv' "
if DOSES_DATASET_SUBDIRS == [""]:
    cmd_concatenate_radiomics += "'" + RADIOMICS_DIR + "'newdosi*"
else:
    cmd_concatenate_radiomics +=  "'" + RADIOMICS_DIR + "'{{" + str_cmd_dataset_subdirs + "}}/*"
cmd_concatenate_radiomics += " > '" + RADIOMICS_DIR + "'dose_matrix_radiomics.csv"
cmd_concatenate_radiomics += " && gzip '" + RADIOMICS_DIR + "'dose_matrix_radiomics.csv"

# Utils
def get_newdosi_files(wildcards):
    return expand(DOSES_DATASET_DIR + "{newdosi_file}.csv.gz", newdosi_file = [newdosi_file for newdosi_file in list_newdosi_files if wildcards.newdosi_patient in newdosi_file])


# Rules

onstart:
    # Directory creations
    for newdir in [RESULTS_DIR, NII_DIR, RADIOMICS_DIR, METADATA_DIR, ANALYZES_DIR]:
        os.makedirs(newdir, exist_ok = True)
    if os.path.isfile(NII_DIR + "csv2nii.log"):
        os.remove(NII_DIR + "csv2nii.log")
    if os.path.isfile(RADIOMICS_DIR + "feature_extraction.log"):
        os.remove(RADIOMICS_DIR + "feature_extraction.log")

rule all:
    input: 
        RADIOMICS_DIR + "dose_matrix_radiomics.csv.gz"

## Metadata
rule list_newdosi_files:
    input:
        expand(DOSES_DATASET_DIR + "{newdosi_file}.csv.gz", newdosi_file = list_newdosi_files) 
    output:
        METADATA_DIR + "list_newdosi_files.csv"
    shell:
        "./workflow/scripts/awk_list_newdosi_files.sh '" + DOSES_DATASET_DIR + "' > " + METADATA_DIR + "list_newdosi_files.csv"

rule list_newdosi_checks:
    input:
        METADATA_DIR + "list_newdosi_files.csv"
    output:
        METADATA_DIR + "list_newdosi_checks.csv"
    run:
        check_dataset.analyze_dataset(DOSES_DATASET_DIR, METADATA_DIR)

rule report_checks:
    input:
        METADATA_DIR + "list_newdosi_checks.csv"
    output:
        METADATA_DIR + "report_checks.txt"
    run:
        report_checks.print_report(METADATA_DIR)

## Extract radiomics
rule images_nii:
    input:
        get_newdosi_files
    output:
        NII_DIR + "{newdosi_patient}_ID2013A.nii.gz",
        NII_DIR + "{newdosi_patient}_mask_t.nii.gz",
        NII_DIR + "{newdosi_patient}_mask_super_t.nii.gz"
    run:
        logger = setup_logger("csv2nii", NII_DIR + "csv2nii.log", mode_file = "a", creation_msg = False)
        logger.info(f"{wildcards.newdosi_patient}: creation of nii images")
        subdir = os.path.dirname(wildcards.newdosi_patient)
        list_newdosi_files_patient = get_newdosi_files(wildcards)
        list_filenames = [os.path.basename(newdosi_file) for newdosi_file in list_newdosi_files_patient]
        path_csv = DOSES_DATASET_DIR + subdir + "/"
        path_nii = NII_DIR + subdir + "/"
        csv2nii.to_nii(path_csv, path_nii, list_filenames)

rule write_header_radiomics:
    output:
        RADIOMICS_DIR + "header.csv",
        RADIOMICS_DIR + "nbr_features_per_label"
    run:
        feature_extractor.write_header(LABELS_SUPER_T_VOI, LABELS_T_VOI, RADIOMICS_DIR, RADIOMICS_PARAMS_FILE)

rule compute_radiomics:
    input:
        RADIOMICS_DIR + "header.csv",
        RADIOMICS_DIR + "nbr_features_per_label",
        NII_DIR + "{newdosi_patient}_ID2013A.nii.gz",
        NII_DIR + "{newdosi_patient}_mask_t.nii.gz",
        NII_DIR + "{newdosi_patient}_mask_super_t.nii.gz"
    output:    
        RADIOMICS_DIR + "{newdosi_patient}_radiomics.csv"
    run:
        logger = setup_logger("feature_extractor", RADIOMICS_DIR + "feature_extraction.log", mode_file = "a", creation_msg = False)
        logger.info(f"{wildcards.newdosi_patient}: Extraction of radiomics")
        newdosi_filename = os.path.basename(wildcards.newdosi_patient)
        subdir = os.path.dirname(wildcards.newdosi_patient)
        image_path = NII_DIR + subdir + "/" + newdosi_filename + "_ID2013A.nii.gz"
        mask_t_path = NII_DIR + subdir + "/" + newdosi_filename + "_mask_t.nii.gz"
        mask_super_t_path = NII_DIR + subdir + "/" + newdosi_filename + "_mask_super_t.nii.gz"
        with open(RADIOMICS_DIR + "nbr_features_per_label", 'r') as file_nbr:
            nbr_features_per_label = int(file_nbr.read())
        feature_extractor.compute_radiomics(image_path, mask_super_t_path, mask_t_path, 
                                            LABELS_SUPER_T_VOI, LABELS_T_VOI, newdosi_filename, RADIOMICS_DIR, subdir, 
                                            RADIOMICS_PARAMS_FILE, nbr_features_per_label)

rule gather_radiomics:
    input:
        expand(RADIOMICS_DIR + "{newdosi_patient}_radiomics.csv", newdosi_patient = list_newdosi_patients)
    output:
        RADIOMICS_DIR + "dose_matrix_radiomics.csv.gz"
    shell:
        cmd_concatenate_radiomics

## Analyses

# Datasets
rule create_dataset:
    input:
        RADIOMICS_DIR + "dose_matrix_radiomics.csv.gz",
        FCCSS_CLINICAL_DATASET
    output:
        ANALYZES_DIR + "datasets/dataset.csv.gz",
    run:
        file_radiomics = RADIOMICS_DIR + "dose_matrix_radiomics.csv.gz"
        trainset.create_dataset(file_radiomics, FCCSS_CLINICAL_DATASET, ANALYZES_DIR, FCCSS_CLINICAL_VARIABLES, EVENT_COL, DATE_EVENT_COL)

rule split_dataset:
    input:
        ANALYZES_DIR + "datasets/dataset.csv.gz",
        FCCSS_CLINICAL_DATASET
    output:
        ANALYZES_DIR + "datasets/trainset.csv.gz",
        ANALYZES_DIR + "datasets/testset.csv.gz"
    run:
        file_radiomics = RADIOMICS_DIR + "dose_matrix_radiomics.csv.gz"
        trainset.split_dataset(file_radiomics, FCCSS_CLINICAL_DATASET, ANALYZES_DIR, FCCSS_CLINICAL_VARIABLES, EVENT_COL, DATE_EVENT_COL)

rule multiple_splits_dataset:
    input:
        ANALYZES_DIR + "datasets/dataset.csv.gz",
        FCCSS_CLINICAL_DATASET
    output:
        expand(ANALYZES_DIR + "datasets/trainset_{nb_set}.csv.gz", nb_set = range(NB_ESTIM_SCORE_MODELS)),
        expand(ANALYZES_DIR + "datasets/testset_{nb_set}.csv.gz", nb_set = range(NB_ESTIM_SCORE_MODELS))
    run:
        file_radiomics = RADIOMICS_DIR + "dose_matrix_radiomics.csv.gz"
        for i in range(NB_ESTIM_SCORE_MODELS):
            trainset.split_dataset(file_radiomics, FCCSS_CLINICAL_DATASET, ANALYZES_DIR, FCCSS_CLINICAL_VARIABLES, EVENT_COL, DATE_EVENT_COL, end_name_sets = f"_{i}")

# Visualisation
rule pca_visualisation:
    input:
        ANALYZES_DIR + "datasets/dataset.csv.gz"
    output:
        ANALYZES_DIR + "pca_viz.log",
        ANALYZES_DIR + "pca/pca_radiomics_all.png"
    run:
        trainset.pca_viz(ANALYZES_DIR + "datasets/dataset.csv.gz", EVENT_COL, ANALYZES_DIR)

# Feature elimination
rule feature_elimination_dataset_hclust_corr:
    input:
        ANALYZES_DIR + "datasets/trainset.csv.gz"
    output: 
        ANALYZES_DIR + "features_hclust_corr.csv",
        ANALYZES_DIR + "feature_elimination_hclust_corr.log"
    run:
        trainset.feature_elimination_hclust_corr(ANALYZES_DIR + "datasets/trainset.csv.gz", EVENT_COL, ANALYZES_DIR)

# Models
rule baseline_analysis:
    input:
        ANALYZES_DIR + "datasets/trainset.csv.gz",
        ANALYZES_DIR + "datasets/testset.csv.gz"
    output:
        ANALYZES_DIR + "baseline_models.log",
        expand(ANALYZES_DIR + "coxph_plots/coefs_{model}.png", model = BASELINE_MODELS_COX),
        expand(ANALYZES_DIR + "coxph_results/metrics_{model}.csv", model = BASELINE_MODELS_COX),
        expand(ANALYZES_DIR + "coxph_plots/coefs_{model}.png", model = BASELINE_MODELS_LASSO),
        expand(ANALYZES_DIR + "coxph_plots/mean_error_alphas_{model}.png", model = BASELINE_MODELS_LASSO),
        expand(ANALYZES_DIR + "coxph_plots/regularization_path_{model}.png", model = BASELINE_MODELS_LASSO),
        expand(ANALYZES_DIR + "coxph_results/cv_{model}.csv", model = BASELINE_MODELS_LASSO),
        expand(ANALYZES_DIR + "coxph_results/best_params_{model}.csv", model = BASELINE_MODELS_LASSO),
        expand(ANALYZES_DIR + "coxph_results/metrics_{model}.csv", model = BASELINE_MODELS_LASSO)
    threads:
        get_ncpus() - 1
    run:
        learning.baseline_models_analysis(ANALYZES_DIR + "datasets/trainset.csv.gz", ANALYZES_DIR + "datasets/testset.csv.gz", EVENT_COL, ANALYZES_DIR)

rule multiple_scores_baseline_models:
    input:
        expand(ANALYZES_DIR + "datasets/trainset_{nb_set}.csv.gz", nb_set = range(NB_ESTIM_SCORE_MODELS)),
        expand(ANALYZES_DIR + "datasets/testset_{nb_set}.csv.gz", nb_set = range(NB_ESTIM_SCORE_MODELS)),
        expand(ANALYZES_DIR + "coxph_results/best_params_{model}.csv", model = BASELINE_MODELS_LASSO)
    output: 
        ANALYZES_DIR + "multiple_scores_baseline_models.log",
        expand(ANALYZES_DIR + "coxph_results/" + str(NB_ESTIM_SCORE_MODELS) + "_runs_test_metrics_{model}.csv", model = BASELINE_MODELS_COX + BASELINE_MODELS_LASSO)
    threads:
        get_ncpus() - 1
    run:
        learning.multiple_scores_baseline_models(NB_ESTIM_SCORE_MODELS, EVENT_COL, ANALYZES_DIR)

rule cox_lasso_radiomics:
    input:
        ANALYZES_DIR + "datasets/trainset.csv.gz",
        ANALYZES_DIR + "datasets/testset.csv.gz",
        ANALYZES_DIR + "features_hclust_corr.csv"
    output:
        ANALYZES_DIR + "cox_lasso_radiomics.log",
        expand(ANALYZES_DIR + "coxph_plots/coefs_{model}.png", model = COX_RADIOMICS_LASSO),
        expand(ANALYZES_DIR + "coxph_plots/mean_error_alphas_{model}.png", model = COX_RADIOMICS_LASSO),
        expand(ANALYZES_DIR + "coxph_plots/regularization_path_{model}.png", model = COX_RADIOMICS_LASSO),
        expand(ANALYZES_DIR + "coxph_results/cv_{model}.csv", model = COX_RADIOMICS_LASSO),
        expand(ANALYZES_DIR + "coxph_results/best_params_{model}.csv", model = COX_RADIOMICS_LASSO),
        expand(ANALYZES_DIR + "coxph_results/metrics_{model}.csv", model = COX_RADIOMICS_LASSO)
    threads:
        get_ncpus() - 1
    run:
        learning.cox_lasso_radiomics(ANALYZES_DIR + "datasets/trainset.csv.gz", ANALYZES_DIR + "features_hclust_corr.csv", ANALYZES_DIR + "datasets/testset.csv.gz", EVENT_COL, ANALYZES_DIR)

rule multiple_scores_cox_lasso_radiomics:
    input:
        ANALYZES_DIR + "features_hclust_corr.csv",
        expand(ANALYZES_DIR + "datasets/trainset_{nb_set}.csv.gz", nb_set = range(NB_ESTIM_SCORE_MODELS)),
        expand(ANALYZES_DIR + "datasets/testset_{nb_set}.csv.gz", nb_set = range(NB_ESTIM_SCORE_MODELS)),
        expand(ANALYZES_DIR + "coxph_results/best_params_{model}.csv", model = COX_RADIOMICS_LASSO)
    output: 
        ANALYZES_DIR + "multiple_scores_cox_lasso_radiomics.log",
        expand(ANALYZES_DIR + "coxph_results/" + str(NB_ESTIM_SCORE_MODELS) + "_runs_test_metrics_{model}.csv", model = COX_RADIOMICS_LASSO)
    threads:
        get_ncpus() - 1
    run:
        learning.multiple_scores_cox_lasso_radiomics(NB_ESTIM_SCORE_MODELS, ANALYZES_DIR + "features_hclust_corr.csv", EVENT_COL, ANALYZES_DIR)

rule rsf_analysis:
    input:
        ANALYZES_DIR + "datasets/trainset.csv.gz",
        ANALYZES_DIR + "datasets/testset.csv.gz"
    output:
        ANALYZES_DIR + "rsf_all.log",
        expand(ANALYZES_DIR + "rsf_plots/rsf_vimp_{model}.png", model = RSF_RADIOMICS_ALL),
        expand(ANALYZES_DIR + "rsf_results/cv_{model}.csv", model = RSF_RADIOMICS_ALL),
        expand(ANALYZES_DIR + "rsf_results/metrics_{model}.csv", model = RSF_RADIOMICS_ALL)
    conda:
        "envs/rsf_R_env.yaml"
    threads:
        get_ncpus() - 1
    shell:
        f"Rscript workflow/scripts/rsf_learning.R {ANALYZES_DIR}datasets/trainset.csv.gz {ANALYZES_DIR}datasets/testset.csv.gz all {EVENT_COL} {ANALYZES_DIR} all"
 
rule rsf_features_hclust_corr_analysis:
    input:
        ANALYZES_DIR + "datasets/trainset.csv.gz",
        ANALYZES_DIR + "datasets/testset.csv.gz",
        ANALYZES_DIR + "features_hclust_corr.csv"
    output:
        ANALYZES_DIR + "rsf_features_hclust_corr.log",
        expand(ANALYZES_DIR + "rsf_plots/rsf_vimp_{model}.png", model = RSF_RADIOMICS_FE_HCLUST),
        expand(ANALYZES_DIR + "rsf_results/cv_{model}.csv", model = RSF_RADIOMICS_FE_HCLUST),
        expand(ANALYZES_DIR + "rsf_results/metrics_{model}.csv", model = RSF_RADIOMICS_FE_HCLUST)
    conda:
        "envs/rsf_R_env.yaml"
    threads:
        get_ncpus() - 1
    shell:
        f"Rscript workflow/scripts/rsf_learning.R {ANALYZES_DIR}datasets/trainset.csv.gz {ANALYZES_DIR}datasets/testset.csv.gz {ANALYZES_DIR}features_hclust_corr.csv {EVENT_COL} {ANALYZES_DIR} features_hclust_corr"


